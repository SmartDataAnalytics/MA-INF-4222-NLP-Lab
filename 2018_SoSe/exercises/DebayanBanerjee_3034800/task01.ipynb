{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import corpus\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import cess_esp as spanish\n",
    "\n",
    "#import classifier stuff\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import some necessary stuff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor and other necessary functions\n",
    "\n",
    "# Feature Extractor\n",
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1]\n",
    "    }\n",
    "\n",
    "# Un-tag Sentences\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]\n",
    "\n",
    "# Apply\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    W, X, y = [], [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            W.append(untag(tagged)[index])\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return W, X, y\n",
    "\n",
    "\n",
    "def classifier(name):\n",
    "    if name == 'logistic':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression()       \n",
    "    elif name == 'decision-tree':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier()       \n",
    "    elif name =='MLP':\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        MLPClassifier(alpha=1)\n",
    "    elif name == 'GaussianNB':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()     \n",
    "    else:\n",
    "        raise NotImplementedError('Classifier not implemented.')    \n",
    "    \n",
    "    clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', classifier)\n",
    "    ])\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "# Treebank\n",
    "treebank_tag = treebank.tagged_sents()\n",
    "\n",
    "# Brown\n",
    "brown_tag = brown.tagged_sents()\n",
    "\n",
    "# Split Dataset\n",
    "test_fraction = 0.2\n",
    "treebank_train, treebank_test = train_test_split(treebank_tag, test_size=test_fraction)\n",
    "brown_train, brown_test = train_test_split(brown_tag, test_size=test_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "W_treebank_train, X_treebank_train, Y_treebank_train = transform_to_dataset(treebank_train)\n",
    "W_treebank_test, X_treebank_test, Y_treebank_test = transform_to_dataset(treebank_test)\n",
    "\n",
    "W_brown_train, X_brown_train, Y_brown_train = transform_to_dataset(brown_train)\n",
    "W_brown_test, X_brown_test, Y_brown_test = transform_to_dataset(brown_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier(X_train, Y_train, X_test, Y_test, clf_name):\n",
    "  \n",
    "    clf_name = 'logistic'\n",
    "    clf = classifier(clf_name)\n",
    "    try:\n",
    "        clf.fit(X_train, Y_train)\n",
    "    except MemoryError:\n",
    "        print('Cannot fit a model! MemoryError. Dataset too big will train on 50 percent of sample set')\n",
    "        try:\n",
    "            X_train = X_train[:int(0.5*len(X_train))]\n",
    "            Y_train = Y_train[:int(0.5*len(Y_train))]\n",
    "            clf.fit(X_train, Y_train)\n",
    "        except MemoryError:\n",
    "            print('Cannot fit a model! MemoryError. Dataset too big will train on 25 percent of sample set')\n",
    "            try:\n",
    "                X_train = X_train[:int(0.25*len(X_train))]\n",
    "                Y_train = Y_train[:int(0.25*len(Y_train))]\n",
    "                clf.fit(X_train, Y_train)\n",
    "            except MemoryError:\n",
    "                print('Cannot fit a model! MemoryError. Dataset too big will train on 10 percent of sample set')\n",
    "                try:\n",
    "                    X_train = X_train[:int(0.10*len(X_train))]\n",
    "                    Y_train = Y_train[:int(0.10*len(Y_train))]\n",
    "                    clf.fit(X_train, Y_train)                \n",
    "                except MemoryError:\n",
    "                    print('Cannot fit a model! MemoryError. Dataset too big select smaller sample set')\n",
    "    return clf.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging_pretrained_model(W_test, Y_test, pretrained_file):\n",
    "    \n",
    "    try:\n",
    "        pretrained_tagger = nltk.data.load(pretrained_file)\n",
    "        tag_test_data = pretrained_tagger.tag(W_test)\n",
    "    except LookupError:\n",
    "        print('Pretrained Model Not exist in NLTK. Using pretrained model based on perceptron')\n",
    "        tag_test_data = nltk.pos_tag(W_test)\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    for pretrained_tag, true_tag in zip(tag_test_data, Y_test):\n",
    "        if pretrained_tag[1] == true_tag:\n",
    "            correct_prediction += 1\n",
    "    return correct_prediction/float(len(tag_test_data))\n",
    "    # Evaluate pre-trained Model on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_classifier(X_train, X_test):\n",
    "    \n",
    "    patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD'), (r'.*es$', 'VBZ'), (r'.*ould$', 'MD'), (r'.*\\'s$', 'NN$'),               \n",
    "             (r'.*s$', 'NNS'), (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), (r'.*', 'NN')]\n",
    "    # Train Different Tagger\n",
    "    def_model = nltk.DefaultTagger('NN')\n",
    "    uni_model = nltk.UnigramTagger(X_train)\n",
    "    bi_model = nltk.BigramTagger(X_train)\n",
    "    tri_model = nltk.TrigramTagger(X_train)\n",
    "    regexp_model = nltk.RegexpTagger(patterns)\n",
    "    \n",
    "    accuracy_def_test = def_model.evaluate(X_test)\n",
    "    accuracy_uni_test = uni_model.evaluate(X_test)\n",
    "    accuracy_bi_test = bi_model.evaluate(X_test)\n",
    "    accuracy_tri_test = tri_model.evaluate(X_test)\n",
    "    accuracy_regexp_test = regexp_model.evaluate(X_test)\n",
    "    \n",
    "    # performance of Default Tagger\n",
    "    print('Default Tagger Accuracy on Training Set {0:.2f}'.format(def_model.evaluate(X_train)))\n",
    "    print('Default Tagger Accuracy on Test Set {0:.2f}'.format(accuracy_def_test))\n",
    "    print()\n",
    "    # performance of Unigram Tagger\n",
    "    print('Unigram Tagger Accuracy on Training Set {0:.2f}'.format(uni_model.evaluate(X_train)))\n",
    "    print('Unigram Tagger Accuracy on Test Set {0:.2f}'.format(accuracy_uni_test))\n",
    "    print()\n",
    "    # performance of Bigram Tagger\n",
    "    print('Bigram Tagger Accuracy on Training Set {0:.2f}'.format(bi_model.evaluate(X_train)))\n",
    "    print('Bigram Tagger Accuracy on Test Set {0:.2f}'.format(accuracy_bi_test))\n",
    "    print()\n",
    "    # performance of Trigram Tagger\n",
    "    print('Trigram Tagger Accuracy on Training Set {0:.2f}'.format(tri_model.evaluate(treebank_train)))\n",
    "    print('Trigram Tagger Accuracy on Test Set {0:.2f}'.format(accuracy_tri_test))\n",
    "    print()\n",
    "    # performance of Regex Tagger\n",
    "    print('Regex Tagger Accuracy on Training Set {0:.2f}'.format(regexp_model.evaluate(X_train)))\n",
    "    print('Regex Tagger Accuracy on Test Set {0:.2f}'.format(accuracy_regexp_test))\n",
    "    print()\n",
    "    \n",
    "    return [accuracy_def_test, accuracy_uni_test, accuracy_bi_test, accuracy_tri_test, accuracy_regexp_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) POS tagger Model for TreeBank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot fit a model! MemoryError. Dataset too big will train on 50 percent of sample set\n",
      "Cannot fit a model! MemoryError. Dataset too big will train on 25 percent of sample set\n",
      "Accuracy on Test Set for TreeBank 0.89 \n"
     ]
    }
   ],
   "source": [
    "clf_name = 'logistic'\n",
    "accuracy_treebank = train_test_classifier(X_treebank_train, Y_treebank_train, X_treebank_test, Y_treebank_test, clf_name)\n",
    "print('Accuracy on Test Set for TreeBank {0:.2f} '.format(accuracy_treebank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Pre-trained Model Using NLTK Max-Entropy for TreeBank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set for TreeBank using pretrained model 0.99 \n"
     ]
    }
   ],
   "source": [
    "pretrained_file = 'taggers/maxent_treebank_pos_tagger/english.pickle'\n",
    "\n",
    "accuracy_treebank_pretrained = pos_tagging_pretrained_model(W_treebank_test, Y_treebank_test, pretrained_file)\n",
    "print('Accuracy on Test Set for TreeBank using pretrained model {0:.2f} '.format(accuracy_treebank_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Rule Based Classifier for TreeBank Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation On TreeBank\n",
      "Default Tagger Accuracy on Training Set 0.13\n",
      "Default Tagger Accuracy on Test Set 0.13\n",
      "\n",
      "Unigram Tagger Accuracy on Training Set 0.96\n",
      "Unigram Tagger Accuracy on Test Set 0.88\n",
      "\n",
      "Bigram Tagger Accuracy on Training Set 0.91\n",
      "Bigram Tagger Accuracy on Test Set 0.15\n",
      "\n",
      "Trigram Tagger Accuracy on Training Set 0.91\n",
      "Trigram Tagger Accuracy on Test Set 0.09\n",
      "\n",
      "Regex Tagger Accuracy on Training Set 0.22\n",
      "Regex Tagger Accuracy on Test Set 0.22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation On TreeBank')\n",
    "accuracy_def_test_tb, accuracy_uni_test_tb, accuracy_bi_test_tb, accuracy_tri_test_tb, accuracy_regexp_test_tb = rule_based_classifier(treebank_train, treebank_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)  POS tagger Model for Brown Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot fit a model! MemoryError. Dataset too big will train on 50 percent of sample set\n",
      "Cannot fit a model! MemoryError. Dataset too big will train on 25 percent of sample set\n",
      "Cannot fit a model! MemoryError. Dataset too big will train on 10 percent of sample set\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c85f29862684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_brown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_brown_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_brown_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_brown_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_brown_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on Test Set for Brown Corpus {0:.2f} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_brown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6857c98ca769>\u001b[0m in \u001b[0;36mtrain_test_classifier\u001b[0;34m(X_train, Y_train, X_test, Y_test, clf_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot fit a model! MemoryError. Dataset too big select smaller sample set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/feature_extraction/dict_vectorizer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tosequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mXa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_brown = train_test_classifier(X_brown_train, Y_brown_train, X_brown_test, Y_brown_test, 'logistic')\n",
    "print('Accuracy on Test Set for Brown Corpus {0:.2f} '.format(accuracy_brown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Pre-trained Model Using NLTK Max-Entropy for TreeBank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Model Not exist in NLTK. Using pretrained model based on perceptron\n",
      "Accuracy on Test Set for Brown Corpus using pretrained model 0.62 \n"
     ]
    }
   ],
   "source": [
    "pretrained_file = 'taggers/maxent_brown_pos_tagger/english.pickle'\n",
    "\n",
    "accuracy_brown_pretrained = pos_tagging_pretrained_model(W_brown_test, Y_brown_test, pretrained_file)\n",
    "print('Accuracy on Test Set for Brown Corpus using pretrained model {0:.2f} '.format(accuracy_brown_pretrained))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Rule Based Classifier for Brown Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation On Brown\n",
      "Default Tagger Accuracy on Training Set 0.13\n",
      "Default Tagger Accuracy on Test Set 0.13\n",
      "\n",
      "Unigram Tagger Accuracy on Training Set 0.92\n",
      "Unigram Tagger Accuracy on Test Set 0.90\n",
      "\n",
      "Bigram Tagger Accuracy on Training Set 0.82\n",
      "Bigram Tagger Accuracy on Test Set 0.31\n",
      "\n",
      "Trigram Tagger Accuracy on Training Set 0.04\n",
      "Trigram Tagger Accuracy on Test Set 0.16\n",
      "\n",
      "Regex Tagger Accuracy on Training Set 0.20\n",
      "Regex Tagger Accuracy on Test Set 0.19\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation On Brown')\n",
    "accuracy_def_test_brown, accuracy_uni_test_brown, accuracy_bi_test_brown, accuracy_tri_test_brown, accuracy_regexp_test_brown = rule_based_classifier(brown_train, brown_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Classifier vs Accuracy for Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_brown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-56c559293a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtreebank_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy_treebank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_treebank_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_def_test_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_uni_test_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_bi_test_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_tri_test_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_regexp_test_tb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbrown_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_brown_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_def_test_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_uni_test_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_bi_test_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_tri_test_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_regexp_test_brown\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreebank_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtreebank_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtreebank_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_brown' is not defined"
     ]
    }
   ],
   "source": [
    "treebank_results = [accuracy_treebank, accuracy_treebank_pretrained, accuracy_def_test_tb, accuracy_uni_test_tb, accuracy_bi_test_tb, accuracy_tri_test_tb, accuracy_regexp_test_tb]\n",
    "brown_results = [accuracy_brown, accuracy_brown_pretrained, accuracy_def_test_brown, accuracy_uni_test_brown, accuracy_bi_test_brown, accuracy_tri_test_brown, accuracy_regexp_test_brown]\n",
    "\n",
    "x_axis = np.arange(len(treebank_results))\n",
    "treebank_results = [round(i, 2) for i in treebank_results]\n",
    "bar1 = plt.bar(x_axis-0.40, treebank_results, color = 'r', width=0.25, align='center')\n",
    "[plt.text(bar.get_x() + bar.get_width()/5., bar.get_height(), bar.get_height(), ha='center', va='bottom') for bar in bar1]\n",
    "\n",
    "brown_results = [round(i, 2) for i in brown_results]\n",
    "bar2 = plt.bar(x_axis, brown_results, color = 'b', width=0.25, align='center')\n",
    "[plt.text(bar.get_x() + bar.get_width()/5., bar.get_height(), bar.get_height(), ha='center', va='bottom') for bar in bar2]\n",
    "\n",
    "plt.title('Performance of Different Classifier on POS Tagging for TreeBank and Brown Corpus')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xticks(x_axis, (clf_name,'pretrained','DefaultTagger','Unigram','Bigram','Trigram','Regex'), rotation='vertical')\n",
    "plt.legend((bar1[0], bar2[0]), ('TreeBank', 'Brown'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) POS Tagger Model for Spanish Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "spanish_tag = spanish.tagged_sents()\n",
    "\n",
    "# Split Dataset\n",
    "test_fraction = 0.2\n",
    "spanish_train, spanish_test = train_test_split(spanish_tag, test_size=test_fraction)\n",
    "\n",
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0] if sentence[index] != '' else False,\n",
    "        'prefix-1': sentence[index][0] if sentence[index] != '' else '',\n",
    "        'suffix-1': sentence[index][-1] if sentence[index] != '' else '',\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1]\n",
    "    }\n",
    "\n",
    "# Create Features\n",
    "W_spanish_train, X_spanish_train, Y_spanish_train = transform_to_dataset(spanish_train)\n",
    "W_spanish_test, X_spanish_test, Y_spanish_test = transform_to_dataset(spanish_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'logistic'\n",
    "accuracy_spanish = train_test_classifier(X_spanish_train, Y_spanish_train, X_spanish_test, Y_spanish_test, clf_name)\n",
    "print('Accuracy on Test Set for Spanish Corpus {0:.2f} '.format(accuracy_spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) POS Pre-trained Model for Spanish Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TREETAGGER_HOME'] = \"/home/debayan/Desktop/academics_parent/academics/MA-INF-4222-NLP-Lab/2018_SoSe/exercises/DebayanBanerjee_3034800/cmd\"\n",
    "\n",
    "from treetagger import TreeTagger\n",
    "\n",
    "treetagger_spanish = TreeTagger(language='spanish')\n",
    "tag_test_data = treetagger_spanish.tag(W_spanish_test)\n",
    "correct_prediction = 0\n",
    "for pretrained_tag, true_tag in zip(tag_test_data, Y_spanish_test):\n",
    "    if pretrained_tag[1] == true_tag:\n",
    "        correct_prediction += 1\n",
    "accuracy_spanish_pretrained = correct_prediction/float(len(tag_test_data))\n",
    "print('Accuracy on Test Set for Spanish Corpus using pretrained model {} '.format(accuracy_spanish_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_results = [accuracy_spanish, accuracy_spanish_pretrained]\n",
    "spanish_results = [round(i, 2) for i in spanish_results]\n",
    "\n",
    "x_axis = np.arange(len(spanish_results))\n",
    "bar = plt.bar(x_axis, spanish_results, color = 'r', width=0.25, align='center')\n",
    "[plt.text(bar.get_x() + bar.get_width()/5., bar.get_height(), bar.get_height(), ha='center', va='bottom') for bar in bar]\n",
    "\n",
    "plt.title('Performance of Different Classifier on POS Tagging for Spanish')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
