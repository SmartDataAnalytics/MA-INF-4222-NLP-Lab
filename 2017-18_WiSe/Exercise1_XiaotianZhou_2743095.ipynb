{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131\n",
      "783\n",
      "3131\n",
      "783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import DefaultTagger as df\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt\n",
    "from nltk import TrigramTagger as tg\n",
    "\n",
    "# load the tagged sentences of treebank data\n",
    "treebank_tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "# Split the dataset for training and testing\n",
    "cutoff = int(.80 * len(treebank_tagged_sentences))\n",
    "treebank_train_sents = treebank_tagged_sentences[:cutoff]\n",
    "treebank_test_sents = treebank_tagged_sentences[cutoff:]\n",
    "print len(treebank_train_sents)\n",
    "print len(treebank_test_sents)\n",
    "\n",
    "# load the tagged sentences of brown data\n",
    "brown_tagged_sentences = nltk.corpus.brown.tagged_sents()[:len(treebank_tagged_sentences)]\n",
    "\n",
    "# Split the dataset for training and testing\n",
    "cutoff = int(.80 * len(brown_tagged_sentences))\n",
    "brown_train_sents = brown_tagged_sentences[:cutoff]\n",
    "brown_test_sents = brown_tagged_sentences[cutoff:]\n",
    "print len(brown_train_sents)\n",
    "print len(brown_test_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to strip the tags from our tagged corpus and feed it to our classifier\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w,t in tagged_sentence]\n",
    "\n",
    "#define what features to use\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence:[w1, w2, ...], index: th index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "\n",
    "#build the training set by a trasformation operation\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    \"\"\" X stores the features state of each word in target sentences set, y stores the coresponding tags \"\"\"\n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return X, y\n",
    "\n",
    "X_treebank_train, y_treebank_train = transform_to_dataset(treebank_train_sents)\n",
    "X_brown_train,y_brown_train = transform_to_dataset(brown_train_sents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Done\n",
      "Accuracy of treebank data: 0.852088427566\n",
      "training ...\n",
      "Done\n",
      "Accuracy of brown data: 0.709691629956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "X_treebank_test, y_treebank_test = transform_to_dataset(treebank_test_sents)\n",
    "X_brown_test, y_brown_test = transform_to_dataset(brown_test_sents)\n",
    "\n",
    "print('training ...')\n",
    "clf.fit(X_treebank_train[:10000], y_treebank_train[:10000])  \n",
    "print('Done')\n",
    "gaussian_treebank = clf.score(X_treebank_test, y_treebank_test)\n",
    "print \"Accuracy of treebank data:\", gaussian_treebank\n",
    "\n",
    "print('training ...')\n",
    "clf.fit(X_brown_train[:10000], y_brown_train[:10000])\n",
    "print('Done')\n",
    "gaussian_brown = clf.score(X_brown_test, y_brown_test)\n",
    "print \"Accuracy of brown data:\", gaussian_brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995689141404\n",
      "0.570638842267\n"
     ]
    }
   ],
   "source": [
    "#Pretrained Pos tagger model accuracy\n",
    "Pretrained_tagger = nltk.data.load('taggers/maxent_treebank_pos_tagger/english.pickle')\n",
    "\n",
    "pre_tree = Pretrained_tagger.evaluate(treebank_tagged_sentences)\n",
    "print pre_tree\n",
    "pre_brown = Pretrained_tagger.evaluate(brown_tagged_sentences)\n",
    "print pre_brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of treebank\n",
      "0.144767702979\n",
      "()\n",
      "0.862617895105\n",
      "()\n",
      "0.113329008434\n",
      "()\n",
      "0.0670692150307\n",
      "()\n",
      "0.24232746145\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "##Rule-based POS taggers\n",
    "patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD'), (r'.*es$', 'VBZ'), (r'.*ould$', 'MD'), (r'.*\\'s$', 'NN$'),               \n",
    "             (r'.*s$', 'NNS'), (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), (r'.*', 'NN')]\n",
    "\n",
    "#Training model for treebank\n",
    "def_model_t = nltk.DefaultTagger('NN')\n",
    "uni_model_t = nltk.UnigramTagger(treebank_train_sents)\n",
    "bi_model_t = nltk.BigramTagger(treebank_train_sents)\n",
    "tri_model_t = nltk.TrigramTagger(treebank_train_sents)\n",
    "regexp_model_t = nltk.RegexpTagger(patterns)\n",
    "\n",
    "print \"Performance of treebank\"\n",
    "# performance of Default Tagger\n",
    "model3_1_t = def_model_t.evaluate(treebank_test_sents)\n",
    "print(model3_1_t)\n",
    "print()\n",
    "# performance of Unigram Tagger\n",
    "model3_2_t = uni_model_t.evaluate(treebank_test_sents)\n",
    "print(model3_2_t)\n",
    "print()\n",
    "# performance of Bigram Tagger\n",
    "model3_3_t = bi_model_t.evaluate(treebank_test_sents)\n",
    "print(model3_3_t)\n",
    "print()\n",
    "# performance of Trigram Tagger\n",
    "model3_4_t = tri_model_t.evaluate(treebank_test_sents)\n",
    "print(model3_4_t)\n",
    "print()\n",
    "# performance of Regex Tagger\n",
    "model3_5_t = regexp_model_t.evaluate(treebank_test_sents)\n",
    "print(model3_5_t)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of brown\n",
      "0.127422907489\n",
      "()\n",
      "0.791960352423\n",
      "()\n",
      "0.0883259911894\n",
      "()\n",
      "0.0574339207048\n",
      "()\n",
      "0.184691629956\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "#Training model for brown\n",
    "def_model_b = nltk.DefaultTagger('NN')\n",
    "uni_model_b = nltk.UnigramTagger(brown_train_sents)\n",
    "bi_model_b = nltk.BigramTagger(brown_train_sents)\n",
    "tri_model_b = nltk.TrigramTagger(brown_train_sents)\n",
    "regexp_model_b = nltk.RegexpTagger(patterns)\n",
    "\n",
    "print \"Performance of brown\"\n",
    "# performance of Default Tagger\n",
    "model3_1_b = def_model_b.evaluate(brown_test_sents)\n",
    "print(model3_1_b)\n",
    "print()\n",
    "# performance of Unigram Tagger\n",
    "model3_2_b = uni_model_b.evaluate(brown_test_sents)\n",
    "print(model3_2_b)\n",
    "print()\n",
    "# performance of Bigram Tagger\n",
    "model3_3_b = bi_model_b.evaluate(brown_test_sents)\n",
    "print(model3_3_b)\n",
    "print()\n",
    "# performance of Trigram Tagger\n",
    "model3_4_b = tri_model_b.evaluate(brown_test_sents)\n",
    "print(model3_4_b)\n",
    "print()\n",
    "# performance of Regex Tagger\n",
    "model3_5_b = regexp_model_b.evaluate(brown_test_sents)\n",
    "print(model3_5_b)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~XiaotianZhou/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "#Plot the result for model1 and model2 performanced in treebank and brown data\n",
    "trace1 = go.Bar(\n",
    "            x=['Model1: My Pos tagger', 'Model2: Pretrained Pos tagger'],\n",
    "            y=[gaussian_treebank, pre_tree],\n",
    "            name = 'TreeBank'\n",
    "    )\n",
    "trace2 = go.Bar(\n",
    "            x=['Model1: My Pos tagger', 'Model2: Pretrained Pos tagger'],\n",
    "            y=[gaussian_brown, pre_brown],\n",
    "            name = 'Brown'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Performance of model1&2 in Treebank and Brown',\n",
    "    barmode = 'group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.iplot(fig, filename='Performance of Treebank and Brown on model1&2 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~XiaotianZhou/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1 = go.Bar(\n",
    "            x=['Model3.1', 'Model3.2','Model3.3','Model3.4','Model3.5'],\n",
    "            y=[model3_1_t, model3_2_t,model3_3_t,model3_4_t,model3_5_t],\n",
    "            name = 'TreeBank'\n",
    "    )\n",
    "trace2 = go.Bar(\n",
    "            x=['Model3.1', 'Model3.2','Model3.3','Model3.4','Model3.5'],\n",
    "            y=[model3_1_b, model3_2_b,model3_3_b,model3_4_b,model3_5_b],\n",
    "            name = 'Brown'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Performance of Rule-based model in Treebank and Brown',\n",
    "    barmode = 'group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.iplot(fig, filename='Performance of model3 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
