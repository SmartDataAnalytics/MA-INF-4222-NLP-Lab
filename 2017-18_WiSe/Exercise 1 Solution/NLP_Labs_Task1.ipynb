{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to NLP Labs WiSe 17-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Environment configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Python\n",
    "2. NLTK http://www.nltk.org/install.html\n",
    "3. Jupyter https://jupyter.org/ \n",
    "4. Anaconda https://www.anaconda.com/download\n",
    "\n",
    "use symbols to express math: $$y = x^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saad Khan  Matrk Nummer - 3010290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# maybe you need to download NLTK data\n",
    "#nltk.download('all')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(\"Hello world, lets do something awesome today!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Penn TreeBank (PTB) X1 & Tiger Corpus X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download('treebank')\n",
    "\n",
    "annotated_sent = nltk.corpus.treebank.tagged_sents()\n",
    "print(annotated_sent[0])\n",
    "print(\"Tagged sentences: \", len(annotated_sent))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))\n",
    "#1 for English, 2 for German\n",
    "#seperation(annotated_sent)\n",
    "# tagsets\n",
    "#nltk.download('tagsets')\n",
    "#print(nltk.help.upenn_tagset())\n",
    "\n",
    "#loading german corpus \n",
    "corp = nltk.corpus.ConllCorpusReader('.', 'tiger_release_aug07.corrected.16012013.conll09',\n",
    "                                     ['ignore', 'words', 'ignore', 'ignore', 'pos'],\n",
    "                                     encoding='utf-8')\n",
    "german_tagged_sents = corp.tagged_sents()\n",
    "#seperation(german_tagged_sents)\n",
    "print(\"German Tagged sentences: \", len(german_tagged_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: improve this feature extraction function\n",
    "    \n",
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1]\n",
    "    }\n",
    "def improved_features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:],\n",
    "        #'is_punctuation_mark' : '!' or '?' or '.' or ';' in sentence[index]\n",
    "    }\n",
    "import pprint \n",
    "pprint.pprint(features(['This', 'is', 'a', 'sentence'], 2))\n",
    "#print()\n",
    "#\n",
    "pprint.pprint(improved_features(['This', 'is', 'a', 'sentence'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seperation(annotated_sent):\n",
    "    cutoff = int(.80 * len(annotated_sent))\n",
    "    training_sentences = annotated_sent[:cutoff]\n",
    "    test_sentences = annotated_sent[cutoff:]\n",
    " \n",
    "    #print(len(training_sentences))\n",
    "    #print(len(test_sentences))\n",
    "    return training_sentences,test_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.classify import MaxentClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "def english_models():\n",
    "    size=10000\n",
    "    # training RandomForestClassifier\n",
    "    model1 = Pipeline([\n",
    "        ('vectorizer', DictVectorizer(sparse=False)),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    model1.fit(X[:size], y[:size]) \n",
    "   \n",
    "    print(\"Accuracy of RForest - English:\", scores[0]) #model 1 score\n",
    "\n",
    "    #Training DT Classifier both classifiers using same dataset\n",
    "    clf = Pipeline([\n",
    "        ('vectorizer', DictVectorizer(sparse=False)),\n",
    "        ('classifier', DecisionTreeClassifier(criterion= 'entropy'))\n",
    "    ])\n",
    "    clf.fit(X[:size], y[:size])\n",
    "\n",
    "    print('training Da Done')\n",
    "\n",
    "    #X_test, y_test = transform_to_dataset(test_sentences)\n",
    "\n",
    "    print(\"Accuracy of DT - English:\", clf.score(X_test, y_test))\n",
    "\n",
    "    #Saving model to disk\n",
    "    pickle.dump(clf, open('DT_model.sav', 'wb'))\n",
    "    pickle.dump(model1, open('model1.sav', 'wb'))\n",
    "    \n",
    "    #Maxent Classifier\n",
    "    \n",
    "    #algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "    #maxent_clf = nltk.MaxentClassifier.train(X, algorithm,max_iter=3)\n",
    "    #maxent_clf.show_most_informative_features(10)\n",
    "    return clf,model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def german_model():\n",
    "    size=10000\n",
    "    test_size = 1000\n",
    "    \n",
    "    # training RandomForestClassifier\n",
    "    model4 = Pipeline([\n",
    "        ('vectorizer', DictVectorizer(sparse=False)),\n",
    "        ('classifier', DecisionTreeClassifier(criterion= 'entropy'))\n",
    "    ])\n",
    "   #print('Length of G test ', len(G_test_sentences))\n",
    "    model4.fit(G_x[:size], G_y[:size]) \n",
    "    # X_test, y_test = transform_to_dataset(G_test_sentences[:test_size])\n",
    "    #m4score = model4.score(X_test, y_test)\n",
    "    #print(\"Accuracy of DT - German:\", m4score) #model 4 score\n",
    "    pickle.dump(model4, open('model4.sav', 'wb'))\n",
    "    return model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40377\n",
      "Accuracy of RForest - English: 0.877239383203\n",
      "training Da Done\n",
      "Accuracy of DT - English: 0.881531014522\n",
      "Accuracy of DT - German: 0.833909574468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(features(untag(tagged), index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return X, y\n",
    "training_sentences,test_sentences = seperation(annotated_sent)\n",
    "X, y = transform_to_dataset(training_sentences)\n",
    "\n",
    "#For German language\n",
    "\n",
    "G_training_sentences,G_test_sentences = seperation(german_tagged_sents)\n",
    "print(len(G_training_sentences))\n",
    "G_x,G_y = transform_to_dataset(G_training_sentences)\n",
    "\n",
    "#German and English Language Models\n",
    "clf, model1 = english_models()\n",
    "model4 = german_model()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function call along with option just to know which classifier to use\n",
    "def pos_tag(sentence,option):\n",
    "    print('checking...')\n",
    "    tagged_sentence = []\n",
    "   # print([features(sentence, index) for index in range(len(sentence))])\n",
    "    if option == 1:\n",
    "        tags = clf.predict([features(sentence, index) for index in range(len(sentence))])\n",
    "    else:\n",
    "        tags = model1.predict([improved_features(sentence, index) for index in range(len(sentence))])\n",
    "    \n",
    "    return zip(sentence, tags)\n",
    "\n",
    "#import platform\n",
    "#print(platform.python_version())\n",
    "#option = 1 means to call DTree Classifier and Features provided, option 2 means call RForest classifier with improved features function\n",
    "print(list(pos_tag(word_tokenize('Hello world, lets do something awesome today!'),1)))\n",
    "print(list(pos_tag(word_tokenize('Hello world, lets do something awesome today!'),2)))\n",
    "#print(list(pos_tag(word_tokenize('Hello world, lets do something awesome today!'),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based POS taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **DefaultTagger** that simply tags everything with the same tag\n",
    "\n",
    "2. **RegexpTagger** that applies tags according to a set of regular expressions\n",
    "\n",
    "3. ** N-Gram** (n-gram tagger is a generalization of a unigram tagger whose context is the current word together with the part-of-speech tags of the n-1 preceding token)\n",
    "    - **UnigramTagger**\n",
    "    - **BigramTagger**\n",
    "    - **TrigramTagger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Models in X1\n",
      "Evaluation of Models in X2\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGxCAYAAAC5hxYeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1688064aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk import DefaultTagger as df\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt\n",
    "from nltk import TrigramTagger as tg\n",
    "import treetaggerwrapper\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "\n",
    "patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD'), (r'.*es$', 'VBZ'), (r'.*ould$', 'MD'), (r'.*\\'s$', 'NN$'),               \n",
    "             (r'.*s$', 'NNS'), (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), (r'.*', 'NN')]\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "size = int(len(brown_tagged_sents) * 0.8)\n",
    "#print(len(brown_tagged_sents))\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "scores = []\n",
    "#X1\n",
    "def_model = nltk.DefaultTagger('NN')\n",
    "regexp_model = nltk.RegexpTagger(patterns)\n",
    "uni_model = nltk.UnigramTagger(train_sents,backoff=regexp_model)\n",
    "bi_model = nltk.BigramTagger(train_sents,backoff=uni_model)\n",
    "tri_model = nltk.TrigramTagger(train_sents,backoff=bi_model)\n",
    "\n",
    "model5 = treetaggerwrapper.TreeTagger(TAGLANG='de')\n",
    "##\n",
    "pickle.dump(def_model, open('model3_1.sav', 'wb'))\n",
    "pickle.dump(uni_model, open('model3_2.sav', 'wb'))\n",
    "pickle.dump(bi_model, open('model3_3.sav', 'wb'))\n",
    "pickle.dump(regexp_model, open('model3_4.sav', 'wb'))\n",
    "pickle.dump(tri_model, open('model3_5.sav', 'wb'))\n",
    "\n",
    "size = 10000\n",
    "X_test, y_test = transform_to_dataset(test_sentences)\n",
    "#print('Length of test ', len(test_sentences))\n",
    "scores.append(model1.score(X_test, y_test))\n",
    "\n",
    "print(\"Evaluation of Models in X1\")\n",
    "\n",
    "# performance of Default Tagger\n",
    "scores.append(def_model.evaluate(test_sentences)) # 1.3.1\n",
    "#print(def_model.evaluate(test_sentences))\n",
    "#print()\n",
    "\n",
    "# performance of Unigram Tagger\n",
    "scores.append(uni_model.evaluate(test_sentences)) # 1.3.2\n",
    "#print(uni_model.evaluate(test_sentences))\n",
    "#print()\n",
    "\n",
    "# performance of Bigram Tagger\n",
    "scores.append(bi_model.evaluate(test_sentences)) # 1.3.3\n",
    "#print(bi_model.evaluate(test_sentences))\n",
    "#print()\n",
    "\n",
    "# performance of Trigram Tagger\n",
    "scores.append(tri_model.evaluate(test_sentences)) # 1.3.4\n",
    "#print(tri_model.evaluate(test_sentences))\n",
    "#print()\n",
    "\n",
    "# performance of Regex Tagger\n",
    "scores.append(regexp_model.evaluate(test_sentences)) # 1.3.5\n",
    "#print(regexp_model.evaluate(test_sentences))\n",
    "X_test, y_test = transform_to_dataset(test_sents)\n",
    "scores.append(model1.score(X_test,y_test)) #1.4\n",
    "\n",
    "print(\"Evaluation of Models in X2\")\n",
    "# performance of Default Tagger\n",
    "#print(def_model.evaluate(train_sents))\n",
    "scores.append(def_model.evaluate(test_sents)) # 1.6.1\n",
    "#print(def_model.evaluate(test_sents))\n",
    "#print()\n",
    "# performance of Unigram Tagger\n",
    "#print(uni_model.evaluate(train_sents))\n",
    "scores.append(uni_model.evaluate(test_sents)) # 1.6.2\n",
    "#print()\n",
    "# performance of Bigram Tagger\n",
    "#print(bi_model.evaluate(train_sents))\n",
    "scores.append(bi_model.evaluate(test_sents)) # 1.6.3\n",
    "#print()\n",
    "# performance of Trigram Tagger\n",
    "#print(tri_model.evaluate(train_sents))\n",
    "scores.append(tri_model.evaluate(test_sents)) # 1.6.4\n",
    "#print()\n",
    "# performance of Regex Tagger\n",
    "#print(regexp_model.evaluate(train_sents))\n",
    "scores.append(regexp_model.evaluate(test_sents)) # 1.6.5\n",
    "\n",
    "X_test, y_test = transform_to_dataset(G_test_sentences[:1000])\n",
    "scores.append(model4.score(X_test, y_test))\n",
    "print(len(scores))\n",
    "\n",
    "objects = ('1.1', '1.3.1', '1.3.2', '1.3.3', '1.3.4', '1.3.5', '1.4','1.6.1','1.6.2','1.6.3','1.6.4','1.6.5','2.2')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.bar(y_pos, scores, align='center', alpha=1)\n",
    "\n",
    "plt.title('Performance Chart')\n",
    " \n",
    "plt.show()\n",
    "\n",
    "#plot_learning_curve(tri_model, \"accuracy vs. training set size\", X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this lab you will learn how to train your own POS tagger classifier and test it against some pre-trained models\n",
    "\n",
    "#### Pleases implement your code and upload it to git using (jupyter notebook format)\n",
    "\n",
    "#### Classifiers\n",
    "\n",
    "1. ``model1`` = your POS tagger model (english)\n",
    "2. ``model2`` = pre-trained POS tagger model using NLTK (maxentropy english)\n",
    "3. ``model3.x`` = rule-based classifiers (x = 1 to 5)\n",
    "\n",
    "3. ``model4`` = your POS tagger model (not english)\n",
    "4. ``model5`` = pre-trained POS tagger model using RDRPOSTagger [1](http://rdrpostagger.sourceforge.net/) or TreeTagger [2](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) (not english)\n",
    "\n",
    "note: for ``model1`` and ``model3`` you can try different classifiers: Hidden Markov Model, Logistic Regression, Maximum Entropy Markov Models, Decision Trees, Naive Bayes, etc..**choose one**!\n",
    "\n",
    "#### Corpora\n",
    "1. ``X1`` = nltk.corpus.treebank (english)\n",
    "2. ``X2`` = nltk.corpus.brown (english)\n",
    "3. ``X3`` = other language (not english)\n",
    "\n",
    "**note**: data split for training/test = 0.8/0.2 (sequencial)\n",
    "\n",
    "#### Task 1\n",
    "- get results for english (**plot a graph with all classifiers x results**)\n",
    "    - ``performance 1.1`` = ``model1`` in ``X1``\n",
    "    - ``performance 1.2`` = ``model2`` in ``X1``\n",
    "    - ``performance 1.3.x`` = ``model3.x`` in ``X1``\n",
    "    \n",
    "    - ``performance 1.4`` = ``model1`` in ``X2``\n",
    "    - ``performance 1.5`` = ``model2`` in ``X2``\n",
    "    - ``performance 1.6.x`` = ``model3.x`` in ``X2``\n",
    "\n",
    "#### Task 2\n",
    "- train your model with standard features (**plot a graph with all classifiers x results**)\n",
    "    - ``performance 2.1`` = ``model4`` in ``X3``\n",
    "    - ``performance 2.2`` = ``model5`` in ``X3``\n",
    "\n",
    "### notes:\n",
    "\n",
    "#### 1. you can save your trained models using pickle (import pickle)\n",
    "#### 2. please upload your jupyter file to git\n",
    "#### 3. this script just gives a general idea, please organize and comment your code accordingly\n",
    "#### 4. you have to make sure the language you choose is supported for one of the classifiers suggested (see above) AND you are able to find a corpus in that language (example: [Tiger Corpus for German](http://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/TIGERCorpus/download/start.html)). You can also search the Web in order to try to find a pre-trained classifier in your y. If that is not possible, just choose one existing. Please also make sure the language you have choosen _does not_ overlap with other students.\n",
    "#### 5. If you are able to find an annotated corpus and format is CoNLL, you can easly read it using the following method in NLTK:\n",
    "```corp = nltk.corpus.ConllCorpusReader()```\n",
    "#### 6. a nice library to create charts: https://plot.ly/python/bar-charts/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
